| Model            | Parameters | Hardware Requirement (RAM)          | Quality              | Offline-capable | Notes                                          |
| ---------------- | ---------- | ----------------------------------- | -------------------- | --------------- | ---------------------------------------------- |
| Llama 2          | 7B         | 8 - 12 GB                           | Good for basic tasks | Yes             | Open-source, very efficient                    |
| GPT-J            | 6B         | 12 GB                               | Good for basic tasks | Yes             | Open-source, easy to customize                 |
| GPT-NeoX         | 20B        | 20 - 30 GB                          | Very good            | Yes             | Powerful, requires more resources              |
| Ollama (Llama 3) | Up to 13B  | 8â€“16 GB (depending on quantization) | Very good            | Yes             | Easy to use, comes with pre-optimized models   |
| GPT-4 (API)      | 175B       | Cloud-only                          | Excellent            | No              | Best quality, but requires payment (API-based) |
