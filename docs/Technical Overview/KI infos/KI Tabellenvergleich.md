
| Modell           | Parameter  | Hardwarebedarf (RAM)                | Qualität                  | Offline-fähig | Bemerkung                                      |
| ---------------- | ---------- | ----------------------------------- | ------------------------- | ------------- | ---------------------------------------------- |
| Llama 2          | 7B         | 8 - 12 GB                           | Gut für einfache Aufgaben | Ja            | Opens-Source, Sehr Effizient                   |
| GPT - J          | 6B         | 12 GB                               | Gut für einfache Aufgaben | Ja            | Open-Source, leicht anzupassen                 |
| GPT - NeoX       | 20B        | 20 - 30 GB                          | Sehr gut                  | Ja            | Leistungsstark, benötigt mehr Ressourcen.      |
| Ollama (Llama 3) | Bis zu 13B | 8-16GB (abhängig von Quantisierung) | Sehr gut                  | Ja            | Einfach zu nutzen, mit voroptimierten Modellen |
| GPT-4 (API)      | 175B       | Cloud-Only                          | Exzellent                 | Nein          | Beste Qualität , aber kostenpflichtig          |
